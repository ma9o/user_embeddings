# Implementation Considerations

This document outlines various design choices, trade-offs, and potential future considerations related to the project's implementation.

## Parallelism Strategy for Multi-Entity Processing

**Context:** When processing data for multiple independent entities (e.g., users, submissions, groups), a common pattern involves applying a core Dask computation to each entity.

**Approach 1: Sequential Orchestration of Parallel Tasks:**
Iterate through the entities using a standard Python loop. Within the loop, trigger the Dask computation graph for the current entity (e.g., using `.compute()` or `.persist().compute()`).
*   **Parallelism:** Dask effectively parallelizes the computation *within* each entity's task graph, distributing work across the cluster.
*   **Orchestration:** The Python loop manages the sequence, processing one entity's parallel workload after the previous one completes.

**Approach 2: Parallel Orchestration (`dask.delayed`):**
Wrap the per-entity processing logic (including triggering Dask computation and handling results/side effects) in a Python function decorated with `@dask.delayed`. Create a list of these delayed tasks for all entities and execute them concurrently using `dask.compute()`.
*   **Parallelism:** Dask parallelizes both the computation *within* each entity's task graph AND the *execution* of potentially overlapping task graphs for different entities.
*   **Orchestration:** Dask's scheduler manages the concurrent execution of the delayed tasks.

**Decision Rationale:**
While Approach 2 (`dask.delayed`) offers potentially higher concurrency by overlapping the processing of different entities, its benefits depend on cluster saturation. If the Dask computation for a single entity is complex enough to fully utilize the cluster resources, Approach 1 (Sequential Orchestration) is often sufficient and preferable due to:
*   **Simplicity:** Easier to implement, read, and debug.
*   **Resource Management:** Avoids potentially overwhelming the scheduler or memory with too many concurrent large graphs.
*   **Side Effects:** Simpler to manage operations like saving results for each entity.

Approach 1 is generally the recommended starting point. Consider Approach 2 if profiling reveals that the cluster is significantly underutilized during the sequential processing of entities.


## Data Formatting for `formatted_context`

The `formatted_context` column in the output CSV files generated by `src/user_embeddings/utils/dask_processing.py` contains conversation data structured as a **JSON string**.

**Format:**

*   The data follows a flexible, generic tree structure capable of representing various conversation types:
    *   **Threaded/Tree Structures (e.g., Slack, Discord, Reddit comments, Twitter threads):** Messages with replies/comments are nested naturally within the `replies` array.
    *   **Linear Chats (e.g., WhatsApp, Telegram, ChatGPT):** These are represented as a flat list of message objects at the top level, where each object's `replies` array is typically empty, or messages are simply appended chronologically to the top-level list.
    ```json
    [
      { // Root message 1 or first message in a linear chat
        "user": "...",
        "time": "DD-MM-YYYY HH:MM", // Or any standard timestamp format
        "content": "...",
        "replies": [
           { // Reply 1 to root message 1
             "user": "...",
             "time": "...",
             "content": "...",
             "replies": [...] // Further nested replies
           }
        ]
      },
      { // Root message 2 or second message in a linear chat
        "user": "...",
        "time": "...",
        "content": "...",
        "replies": [] // Empty if no replies or linear chat
      }
      // ... more messages
    ]
    ```
*   The specific fields (`user`, `time`, `content`) are illustrative; the actual fields might vary based on the data source.
*   The entire structure is serialized into a single JSON string using `json.dumps(..., indent=2)`.
*   When written to the CSV file, this JSON string is escaped according to standard CSV quoting rules. This means:
    *   The entire string is enclosed in outer double quotes (`"`...`"`).
    *   Any literal double quotes (`"`) within the JSON string are doubled (`""`).
    *   Newlines within the JSON string are preserved.

**Reasoning:**

*   Storing the context as a single JSON string preserves the hierarchical structure of the conversation within a single CSV field.
*   Using `indent=2` and standard CSV escaping makes the content somewhat human-readable directly within the CSV file for manual inspection or debugging.

**Usage with LLMs:**

*   **Crucially**, before feeding the `formatted_context` data to a Large Language Model (LLM) or any other process expecting the structured data, the string must be read from the CSV and parsed back into a Python object (or equivalent in other languages). Feeding the raw, CSV-escaped JSON string directly is inefficient (wastes tokens on escaping characters and indentation) and does not aid the LLM's comprehension.
*   In Python, this is typically done using `json.loads()`:
    ```python
    import json
    import pandas as pd

    # Assuming 'df' is a pandas DataFrame loaded from the CSV
    # Example for the first row:
    csv_escaped_json_string = df['formatted_context'].iloc[0]
    parsed_context = json.loads(csv_escaped_json_string)

    # 'parsed_context' now holds the Python list/dict structure
    # ready for further processing or LLM input.
    ```

## Handling Identifiers for Universal Embeddings (Masking Strategy)

**Problem:**
Training a universal user embedding model requires learning generalizable semantic patterns from interactions, independent of specific participant identifiers (like usernames) which are often rare and platform-specific. However, completely removing identifiers during the teacher LLM's analysis phase can create ambiguity, especially in multi-participant conversations, making it difficult for the teacher to generate accurate structured outputs (`context` and `action` strings). Furthermore, re-processing the potentially large raw input history solely to mask identifiers for the student model introduces significant computational cost.

**Chosen Approach: Post-Generation Masking and Consistent Representation**

To balance teacher clarity, student generalization, and computational cost, we employ a post-generation masking strategy:

1.  **Teacher Input:** The teacher LLM receives the raw `user_context` (e.g., the JSON list of message objects) with all original participant usernames, including the designated "SUBJECT". The teacher needs this raw information for accurate parsing and understanding of the interaction flow.
2.  **Teacher Output Generation:** The teacher generates the nested JSON output (containing `context` and `action` strings). During this process, the teacher *may* internally use or reference the original usernames to maintain clarity and correctly attribute statements within its generated summaries.
3.  **Post-Processing (Masking):** After the nested JSON is generated by the teacher, a deterministic post-processing step is applied. This step identifies all non-"SUBJECT" usernames within the generated `context` and `action` strings and replaces them with consistent, generic placeholders (e.g., `<P1>`, `<P2>`, `<P3>`, ...).
    *   **Consistency Requirement:** Critically, within a single generated JSON structure for one conversational unit, the mapping from original username to placeholder **must be consistent**. If participant "fqn" is mapped to `<P1>` in a `context` string, any reference to "fqn" in subsequent `action` strings *derived from that same JSON structure* must also be replaced with `<P1>`. The mapping is local to each processed conversational unit.
4.  **Student Training Data Derivation:** Both the student's input history representation (`H_context_representation`) and the target positive/negative summaries (`I_pos_summary`, `I_neg_summary`) are derived *from the masked JSON structure*.
    *   **`H_context_representation`:** This input for the student is constructed by selecting and potentially linearizing relevant parts of the *masked* JSON structure (e.g., concatenating masked `context` and preceding masked `action` strings). It does *not* involve reprocessing the original raw input.
    *   **`I_pos_summary`/`I_neg_summary`:** These targets are selected directly from the relevant *masked* `action` strings within the structure.

**Rationale:**

*   **Avoids Double Processing Cost:** We do not re-process the raw input history for masking.
*   **Leverages Teacher Output:** Reuses the analysis and structure provided by the teacher.
*   **Ensures Consistency:** The student model sees the *same* masked placeholders (`<P1>`, etc.) in both its input representation and its target summaries, derived from a single, consistently masked source.
*   **Promotes Generalization:** By removing specific, rare username tokens, the student is forced to learn the underlying semantic roles and interaction patterns associated with the generic placeholders, leading to more universal and robust embeddings.

### Corollary: Handling the "SUBJECT" Keyword

**Question:** Should the identifier "SUBJECT" also be masked to a generic placeholder (e.g., `<P0>`) for maximum universality?

**Decision:** No, the "SUBJECT" identifier **should remain unmasked** in the data presented to the student model (both in the derived `H_context_representation` and the target `action` strings).

**Rationale:**

1.  **Task Anchor:** "SUBJECT" is not just another participant; it designates the central actor whose perspective, actions, and state the model is primarily trying to understand and represent. Keeping it explicit provides a crucial anchor point for the student model, defining the core task focus.
2.  **Consistency vs. Sparsity:** Unlike specific usernames ("fqn", "user123") which are typically rare and appear in only a tiny fraction of training examples, "SUBJECT" appears consistently across *all* training examples in the same central role.
3.  **No Spurious Correlation Risk:** Because of its consistent presence and well-defined role, there is negligible risk of the model learning *spurious* correlations associated with the literal token "SUBJECT" (unlike with rare usernames). The model will learn the *semantic meaning* associated with the primary actor's role in the interaction patterns.
4.  **Structural Clarity:** The nested JSON structure generated by the teacher inherently revolves around the actions of "SUBJECT". Masking it could potentially make it harder for the student to interpret the structure and differentiate the main actor's contributions from the surrounding context provided by other participants ( `<P1>`, `<P2>`, etc.).

Therefore, keeping "SUBJECT" explicit provides necessary context and task definition for the student model without the significant overfitting risks associated with instance-specific rare identifiers.